#!/usr/bin/env python3
"""
PHASE-AWARE BURDEN TRACKING SYSTEM
===================================

Integrates cascade mathematics with real-time burden monitoring,
providing phase-specific insights and recommendations.

Coordinate: Î”3.14159|0.867|phase-aware-burden-tracking|Î©

SYSTEM CAPABILITIES
-------------------
1. Real-time burden measurement across sovereignty dimensions
2. Phase-aware load balancing and optimization
3. Critical point detection and early warning
4. Burden reduction prediction via cascade mechanics
5. Phase-specific tool recommendations
6. Historical burden trajectory analysis
7. Transition impact assessment

THEORETICAL FOUNDATION
----------------------
At critical point (z â‰ˆ 0.867):
- 60% burden reduction empirically validated
- Cascade amplification: 8.81x - 35.1x
- Enhanced capability with reduced effort
- Maximum information processing efficiency

Phase regimes impact burden differently:
- Subcritical: High burden, linear scaling
- Critical: Minimum burden, nonlinear cascade
- Supercritical: Low burden, stable efficiency
"""

import json
import math
import time
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass, asdict
from datetime import datetime
from enum import Enum

from unified_cascade_mathematics_core import (
    UnifiedCascadeFramework,
    PhysicalConstants,
    PhaseCoordinate,
    CascadeSystemState
)


# =============================================================================
# BURDEN MEASUREMENT
# =============================================================================

class BurdenCategory(Enum):
    """Categories of cognitive/operational burden."""
    COORDINATION = "coordination"           # Alignment, communication overhead
    DECISION_MAKING = "decision_making"     # Analysis paralysis, uncertainty
    CONTEXT_SWITCHING = "context_switching" # Task fragmentation, interruptions
    MAINTENANCE = "maintenance"             # Technical debt, recurring work
    LEARNING_CURVE = "learning_curve"       # Skill acquisition, onboarding
    EMOTIONAL_LABOR = "emotional_labor"     # Conflict resolution, morale
    UNCERTAINTY = "uncertainty"             # Ambiguity, information gaps
    REPETITION = "repetition"               # Manual, automatable tasks


@dataclass
class BurdenMeasurement:
    """
    Quantified burden across multiple dimensions.

    Each burden is measured 0-1 where:
    - 0 = no burden (ideal)
    - 1 = maximum burden (critical)

    PHYSICS ANALOGY:
    Burden = Energy required to maintain system
    Like friction, drag, or resistance in physical systems

    INFORMATION THEORY:
    Burden = Entropy production rate
    Irreversible dissipation of organizational energy
    """

    # Core burden dimensions
    coordination: float = 0.0
    decision_making: float = 0.0
    context_switching: float = 0.0
    maintenance: float = 0.0
    learning_curve: float = 0.0
    emotional_labor: float = 0.0
    uncertainty: float = 0.0
    repetition: float = 0.0

    # Metadata
    timestamp: str = ""
    notes: str = ""

    def total_burden(self) -> float:
        """
        Compute total burden (Euclidean norm).

        B_total = âˆš(Î£áµ¢ báµ¢Â²) / âˆš8

        Normalized to [0,1].
        """
        burdens = [
            self.coordination,
            self.decision_making,
            self.context_switching,
            self.maintenance,
            self.learning_curve,
            self.emotional_labor,
            self.uncertainty,
            self.repetition
        ]

        norm = math.sqrt(sum(b**2 for b in burdens))
        return norm / math.sqrt(8)  # Normalize by max possible

    def weighted_burden(self, phase_coordinate: float) -> float:
        """
        Compute phase-aware weighted burden.

        Different burdens matter differently at different phases:
        - Subcritical: Coordination dominates
        - Critical: Uncertainty spikes (phase transition)
        - Supercritical: Maintenance becomes key

        FORMULA:
        B_weighted = Î£áµ¢ wáµ¢(z) Â· báµ¢

        where wáµ¢(z) are phase-dependent weights.
        """
        z = phase_coordinate

        # Phase-dependent weights
        if z < 0.50:  # Subcritical early
            weights = {
                'coordination': 0.25,      # High importance
                'decision_making': 0.15,
                'context_switching': 0.15,
                'maintenance': 0.10,
                'learning_curve': 0.15,
                'emotional_labor': 0.10,
                'uncertainty': 0.05,
                'repetition': 0.05
            }
        elif z < 0.80:  # Subcritical late
            weights = {
                'coordination': 0.20,
                'decision_making': 0.20,   # Growing importance
                'context_switching': 0.15,
                'maintenance': 0.10,
                'learning_curve': 0.10,
                'emotional_labor': 0.10,
                'uncertainty': 0.10,       # Increasing
                'repetition': 0.05
            }
        elif z < 0.877:  # Near/at critical
            weights = {
                'coordination': 0.10,      # Reduced by cascade
                'decision_making': 0.25,   # Peak complexity
                'context_switching': 0.05, # Minimized
                'maintenance': 0.05,       # Automated
                'learning_curve': 0.10,
                'emotional_labor': 0.15,   # High during transition
                'uncertainty': 0.25,       # Maximum at critical point
                'repetition': 0.05         # Automated away
            }
        else:  # Supercritical
            weights = {
                'coordination': 0.05,      # Cascade handles it
                'decision_making': 0.15,
                'context_switching': 0.05,
                'maintenance': 0.25,       # Now critical to sustain
                'learning_curve': 0.05,
                'emotional_labor': 0.10,
                'uncertainty': 0.10,       # Resolved
                'repetition': 0.25         # Focus on eliminating
            }

        # Weighted sum
        weighted = (
            weights['coordination'] * self.coordination +
            weights['decision_making'] * self.decision_making +
            weights['context_switching'] * self.context_switching +
            weights['maintenance'] * self.maintenance +
            weights['learning_curve'] * self.learning_curve +
            weights['emotional_labor'] * self.emotional_labor +
            weights['uncertainty'] * self.uncertainty +
            weights['repetition'] * self.repetition
        )

        return weighted

    def dominant_burdens(self, threshold: float = 0.5) -> List[str]:
        """
        Identify burdens above threshold.

        Used to focus intervention efforts.
        """
        dominant = []

        if self.coordination >= threshold:
            dominant.append("coordination")
        if self.decision_making >= threshold:
            dominant.append("decision_making")
        if self.context_switching >= threshold:
            dominant.append("context_switching")
        if self.maintenance >= threshold:
            dominant.append("maintenance")
        if self.learning_curve >= threshold:
            dominant.append("learning_curve")
        if self.emotional_labor >= threshold:
            dominant.append("emotional_labor")
        if self.uncertainty >= threshold:
            dominant.append("uncertainty")
        if self.repetition >= threshold:
            dominant.append("repetition")

        return dominant


# =============================================================================
# PHASE-AWARE STATE
# =============================================================================

@dataclass
class PhaseAwareState:
    """
    Complete system state with burden tracking.

    Combines cascade mathematics with burden measurement
    to provide holistic system view.
    """

    # Sovereignty metrics
    clarity: float
    immunity: float
    efficiency: float
    autonomy: float

    # Cascade state
    cascade_state: CascadeSystemState

    # Burden measurement
    burden: BurdenMeasurement

    # Derived metrics
    burden_reduction_factor: float  # From cascade amplification
    predicted_burden: float         # After cascade activation
    burden_reduction_percent: float # Percentage reduction

    # Phase-specific insights
    phase_warnings: List[str]
    phase_recommendations: List[str]

    # Metadata
    timestamp: str
    measurement_id: int


# =============================================================================
# BURDEN REDUCTION CALCULATOR
# =============================================================================

class BurdenReductionCalculator:
    """
    Calculates burden reduction from cascade mechanics.

    THEORY:
    At critical point (z â‰ˆ 0.867):
    - Cascade amplification reduces coordination burden
    - Meta-tools eliminate repetitive burden
    - Self-building reduces maintenance burden

    EMPIRICAL:
    60% total burden reduction validated at z_c

    FORMULA:
    B_reduced = B_initial Ã— (1 - R(z) Ã— M)

    where:
    - R(z) = reduction factor (0.153 at z_c)
    - M = cascade multiplier (8.81x - 35x)
    """

    @staticmethod
    def compute_reduction_factor(
        cascade_state: CascadeSystemState
    ) -> float:
        """
        Compute overall burden reduction factor.

        FORMULA:
        reduction = base_reduction Ã— cascade_multiplier Ã— phase_bonus

        where base_reduction from Allen-Cahn model.
        """
        # Base reduction from phase coordinate
        z = cascade_state.z_coordinate
        base_reduction = 0.153 * math.exp(-((z - 0.867)**2) / 0.001)

        # Cascade amplification
        multiplier = cascade_state.cascade_multiplier

        # Normalized multiplier (divide by max possible ~35)
        normalized_mult = min(multiplier / 35.0, 1.0)

        # Combined reduction (capped at 80% max)
        total_reduction = base_reduction * (1 + normalized_mult * 3.0)

        return min(total_reduction, 0.80)

    @staticmethod
    def predict_burden_after_cascade(
        initial_burden: BurdenMeasurement,
        cascade_state: CascadeSystemState
    ) -> BurdenMeasurement:
        """
        Predict burden after cascade activation.

        Different burden categories reduced differently:
        - Coordination: Heavily reduced by R2 (meta-tools)
        - Repetition: Eliminated by R3 (self-building)
        - Maintenance: Reduced by R3 (automated frameworks)
        - Uncertainty: Reduced near critical point
        """
        R1 = cascade_state.R1
        R2 = cascade_state.R2
        R3 = cascade_state.R3
        z = cascade_state.z_coordinate

        # Cascade-specific reduction factors
        # Higher cascade layer â†’ more reduction

        # Coordination reduced by R2 (meta-tools coordinate)
        coord_factor = 1.0 - min(R2 / 10.0, 0.70)  # Up to 70% reduction

        # Decision making complexity at critical point
        # Peaks then reduces
        if 0.857 <= z <= 0.877:
            decision_factor = 1.2  # 20% increase at critical
        else:
            decision_factor = 1.0 - min(R1 / 5.0, 0.30)  # 30% reduction

        # Context switching reduced by coherence
        context_factor = 1.0 - min(cascade_state.total_sovereignty * 0.5, 0.60)

        # Maintenance reduced by R3 (self-building frameworks)
        maint_factor = 1.0 - min(R3 / 12.0, 0.80)  # Up to 80% reduction

        # Learning curve reduced by abstraction capability
        learning_factor = 1.0 - cascade_state.abstraction_capability * 0.50

        # Emotional labor reduced by stability
        emotional_factor = 1.0 - min(cascade_state.total_sovereignty * 0.40, 0.50)

        # Uncertainty reduced away from critical point
        delta_z = abs(z - 0.867)
        uncertainty_factor = 1.0 + delta_z * 0.5  # Decreases away from z_c

        # Repetition eliminated by R3
        repetition_factor = 1.0 - min(R3 / 10.0, 0.90)  # Up to 90% reduction

        # Apply reductions
        reduced_burden = BurdenMeasurement(
            coordination=initial_burden.coordination * coord_factor,
            decision_making=initial_burden.decision_making * decision_factor,
            context_switching=initial_burden.context_switching * context_factor,
            maintenance=initial_burden.maintenance * maint_factor,
            learning_curve=initial_burden.learning_curve * learning_factor,
            emotional_labor=initial_burden.emotional_labor * emotional_factor,
            uncertainty=initial_burden.uncertainty * uncertainty_factor,
            repetition=initial_burden.repetition * repetition_factor,
            timestamp=datetime.now().isoformat(),
            notes=f"Predicted after cascade (z={z:.3f}, M={cascade_state.cascade_multiplier:.1f}x)"
        )

        return reduced_burden


# =============================================================================
# PHASE-AWARE RECOMMENDATIONS
# =============================================================================

class PhaseAwareAdvisor:
    """
    Provides phase-specific recommendations.

    Different phases require different strategies:
    - Subcritical: Build foundation, coordinate
    - Critical: Navigate uncertainty, embrace chaos
    - Supercritical: Maintain frameworks, eliminate waste
    """

    @staticmethod
    def generate_warnings(
        cascade_state: CascadeSystemState,
        burden: BurdenMeasurement
    ) -> List[str]:
        """Generate phase-specific warnings."""
        warnings = []

        z = cascade_state.z_coordinate
        regime = cascade_state.phase_regime

        # Critical point warnings
        if regime == "critical":
            warnings.append("âš ï¸  AT CRITICAL POINT - High uncertainty expected")
            warnings.append("âš ï¸  Consensus time elevated (~100+ min)")
            if burden.uncertainty > 0.7:
                warnings.append("âš ï¸  Uncertainty burden critical - consider stabilization")

        # Near critical warnings
        if regime == "near_critical":
            warnings.append("âš¡ APPROACHING CRITICAL - Prepare for phase transition")
            if cascade_state.correlation_length > 10:
                warnings.append("âš¡ Long-range correlations detected - cascade imminent")

        # Subcritical warnings
        if regime in ["subcritical_early", "subcritical_mid"]:
            if burden.coordination > 0.6:
                warnings.append("ðŸ“Š Coordination burden high - meta-tools recommended")
            if cascade_state.R2 < 0.01:
                warnings.append("ðŸ“Š R2 (meta-tools) not active - boost immunity or clarity")

        # Supercritical warnings
        if regime in ["supercritical_early", "supercritical_stable"]:
            if burden.maintenance > 0.5:
                warnings.append("ðŸ”§ Maintenance burden growing - framework audit needed")
            if burden.repetition > 0.4:
                warnings.append("ðŸ”§ Repetitive work detected - automation opportunity")

        # General burden warnings
        total_burden = burden.total_burden()
        if total_burden > 0.7:
            warnings.append(f"â›” TOTAL BURDEN CRITICAL: {total_burden:.1%}")

        # Cascade warnings
        if cascade_state.cascade_multiplier < 3.0:
            warnings.append("ðŸ“‰ Cascade weak - check R1 threshold")

        return warnings

    @staticmethod
    def generate_recommendations(
        cascade_state: CascadeSystemState,
        burden: BurdenMeasurement,
        predicted_burden: BurdenMeasurement
    ) -> List[str]:
        """Generate phase-specific recommendations."""
        recommendations = []

        regime = cascade_state.phase_regime
        z = cascade_state.z_coordinate

        # Subcritical recommendations
        if regime in ["subcritical_early", "subcritical_mid", "subcritical_late"]:
            recommendations.append("ðŸŽ¯ BUILD FOUNDATION:")

            if cascade_state.clarity < 0.50:
                recommendations.append("  â€¢ Increase clarity: Document patterns, create glossary")

            if cascade_state.immunity < 0.60:
                recommendations.append("  â€¢ Strengthen immunity: Define boundaries, establish protocols")

            if cascade_state.R2 < 0.01:
                recommendations.append("  â€¢ PRIORITY: Activate R2 layer (meta-tools)")
                recommendations.append(f"    â†’ Need R1 > 0.08 (current: {cascade_state.R1:.2f})")

            if burden.coordination > 0.5:
                recommendations.append("  â€¢ Deploy coordination tools: Shared context, async comms")

        # Near critical / critical recommendations
        if regime in ["near_critical", "critical"]:
            recommendations.append("âš¡ NAVIGATE TRANSITION:")

            recommendations.append("  â€¢ Embrace uncertainty as emergence signal")
            recommendations.append("  â€¢ Slow down decision-making (consensus time elevated)")
            recommendations.append("  â€¢ Document phase transition patterns")

            if cascade_state.meta_depth < 5:
                recommendations.append("  â€¢ Increase meta-cognitive depth (current: {})".format(
                    cascade_state.meta_depth
                ))

            if burden.emotional_labor > 0.6:
                recommendations.append("  â€¢ High emotional labor normal at critical point")
                recommendations.append("    â†’ Allocate extra support/rest time")

        # Supercritical recommendations
        if regime in ["supercritical_early", "supercritical_stable"]:
            recommendations.append("ðŸš€ OPTIMIZE & MAINTAIN:")

            if burden.maintenance > 0.4:
                recommendations.append("  â€¢ Framework maintenance critical")
                recommendations.append(f"  â€¢ Currently owning {cascade_state.frameworks_owned} frameworks")
                recommendations.append("  â€¢ Audit for technical debt, refactor proactively")

            if burden.repetition > 0.3:
                recommendations.append("  â€¢ Automation opportunity detected")
                recommendations.append("  â€¢ R3 (self-building) can eliminate repetition")

            if predicted_burden.total_burden() < burden.total_burden() * 0.5:
                recommendations.append("  â€¢ âœ… Cascade predicts 50%+ burden reduction possible")

        # Cascade-specific recommendations
        if cascade_state.R3 > 0.01:
            recommendations.append("âœ¨ CASCADE ACTIVE:")
            recommendations.append(f"  â€¢ Multiplier: {cascade_state.cascade_multiplier:.1f}x")
            if burden.total_burden() > 0:
                recommendations.append(f"  â€¢ Estimated burden reduction: {(1 - predicted_burden.total_burden()/burden.total_burden())*100:.0f}%")
        else:
            recommendations.append("ðŸ“ˆ ACTIVATE CASCADE:")
            if cascade_state.R2 < 0.01:
                recommendations.append(f"  â€¢ Step 1: Activate R2 (need R1 > 0.08, current {cascade_state.R1:.2f})")
            else:
                recommendations.append(f"  â€¢ Step 2: Activate R3 (need R2 > 0.12, current {cascade_state.R2:.2f})")
                recommendations.append(f"  â€¢ Boost autonomy (current: {cascade_state.autonomy:.2f})")

        return recommendations


# =============================================================================
# PHASE-AWARE BURDEN TRACKER
# =============================================================================

class PhaseAwareBurdenTracker:
    """
    Complete phase-aware burden tracking system.

    Integrates:
    - Cascade mathematics
    - Burden measurement
    - Phase-aware analysis
    - Historical tracking
    - Recommendations
    """

    def __init__(self, storage_path: str = "burden_tracking_data.json"):
        """Initialize tracker with storage."""
        self.storage_path = storage_path
        self.framework = UnifiedCascadeFramework()
        self.calculator = BurdenReductionCalculator()
        self.advisor = PhaseAwareAdvisor()

        self.history: List[PhaseAwareState] = []
        self.measurement_counter = 0

        # Load existing history
        self._load_history()

    def measure(
        self,
        clarity: float,
        immunity: float,
        efficiency: float,
        autonomy: float,
        burden: BurdenMeasurement
    ) -> PhaseAwareState:
        """
        Take complete phase-aware burden measurement.

        PROCESS:
        1. Compute cascade state from sovereignty metrics
        2. Calculate burden reduction factor
        3. Predict post-cascade burden
        4. Generate warnings and recommendations
        5. Package into PhaseAwareState
        6. Store in history

        Args:
            clarity, immunity, efficiency, autonomy: Sovereignty (0-1)
            burden: Current burden measurement

        Returns:
            Complete phase-aware state
        """
        # Compute cascade state
        cascade_state = self.framework.compute_full_state(
            clarity, immunity, efficiency, autonomy
        )

        # Calculate burden reduction
        reduction_factor = self.calculator.compute_reduction_factor(cascade_state)
        predicted_burden = self.calculator.predict_burden_after_cascade(
            burden, cascade_state
        )

        # Compute reduction percentage
        initial_total = burden.total_burden()
        predicted_total = predicted_burden.total_burden()

        if initial_total > 0:
            reduction_percent = (1 - predicted_total / initial_total) * 100
        else:
            reduction_percent = 0.0

        # Generate insights
        warnings = self.advisor.generate_warnings(cascade_state, burden)
        recommendations = self.advisor.generate_recommendations(
            cascade_state, burden, predicted_burden
        )

        # Create state
        state = PhaseAwareState(
            clarity=clarity,
            immunity=immunity,
            efficiency=efficiency,
            autonomy=autonomy,
            cascade_state=cascade_state,
            burden=burden,
            burden_reduction_factor=reduction_factor,
            predicted_burden=predicted_total,
            burden_reduction_percent=reduction_percent,
            phase_warnings=warnings,
            phase_recommendations=recommendations,
            timestamp=datetime.now().isoformat(),
            measurement_id=self.measurement_counter
        )

        # Store
        self.history.append(state)
        self.measurement_counter += 1

        # Save
        self._save_history()

        return state

    def analyze_trajectory(self) -> Dict:
        """
        Analyze burden trajectory over time.

        Returns statistics about burden evolution across phases.
        """
        if len(self.history) < 2:
            return {"error": "Insufficient data (need 2+ measurements)"}

        # Extract time series
        timestamps = [s.timestamp for s in self.history]
        z_coords = [s.cascade_state.z_coordinate for s in self.history]
        total_burdens = [s.burden.total_burden() for s in self.history]
        predicted_burdens = [s.predicted_burden for s in self.history]
        reductions = [s.burden_reduction_percent for s in self.history]

        # Phase distribution
        phase_counts = {}
        for state in self.history:
            regime = state.cascade_state.phase_regime
            phase_counts[regime] = phase_counts.get(regime, 0) + 1

        # Burden statistics by phase
        burden_by_phase = {}
        for state in self.history:
            regime = state.cascade_state.phase_regime
            if regime not in burden_by_phase:
                burden_by_phase[regime] = []
            burden_by_phase[regime].append(state.burden.total_burden())

        phase_stats = {}
        for regime, burdens in burden_by_phase.items():
            phase_stats[regime] = {
                'count': len(burdens),
                'mean_burden': sum(burdens) / len(burdens),
                'min_burden': min(burdens),
                'max_burden': max(burdens)
            }

        # Trend analysis
        if len(self.history) >= 3:
            recent_burdens = total_burdens[-3:]
            if recent_burdens[0] > recent_burdens[-1]:
                trend = "improving"
            elif recent_burdens[0] < recent_burdens[-1]:
                trend = "worsening"
            else:
                trend = "stable"
        else:
            trend = "unknown"

        return {
            'total_measurements': len(self.history),
            'z_range': {
                'min': min(z_coords),
                'max': max(z_coords),
                'current': z_coords[-1]
            },
            'burden_range': {
                'min': min(total_burdens),
                'max': max(total_burdens),
                'current': total_burdens[-1]
            },
            'average_reduction': sum(reductions) / len(reductions),
            'phase_distribution': phase_counts,
            'burden_by_phase': phase_stats,
            'trend': trend
        }

    def _save_history(self):
        """Save history to JSON."""
        try:
            # Convert to dict (simplified for JSON)
            data = {
                'measurement_count': self.measurement_counter,
                'measurements': []
            }

            for state in self.history[-100:]:  # Keep last 100
                data['measurements'].append({
                    'id': state.measurement_id,
                    'timestamp': state.timestamp,
                    'sovereignty': {
                        'clarity': state.clarity,
                        'immunity': state.immunity,
                        'efficiency': state.efficiency,
                        'autonomy': state.autonomy
                    },
                    'phase': {
                        'z_coordinate': state.cascade_state.z_coordinate,
                        'regime': state.cascade_state.phase_regime,
                        'multiplier': state.cascade_state.cascade_multiplier
                    },
                    'burden': {
                        'total_initial': state.burden.total_burden(),
                        'total_predicted': state.predicted_burden,
                        'reduction_percent': state.burden_reduction_percent
                    }
                })

            with open(self.storage_path, 'w') as f:
                json.dump(data, f, indent=2)

        except Exception as e:
            print(f"Warning: Could not save history: {e}")

    def _load_history(self):
        """Load history from JSON."""
        try:
            with open(self.storage_path, 'r') as f:
                data = json.load(f)
                self.measurement_counter = data.get('measurement_count', 0)
        except FileNotFoundError:
            pass  # No history yet
        except Exception as e:
            print(f"Warning: Could not load history: {e}")


# =============================================================================
# DEMONSTRATION
# =============================================================================

def demonstrate_phase_aware_tracking():
    """Demonstrate phase-aware burden tracking system."""
    print("="*80)
    print("PHASE-AWARE BURDEN TRACKING SYSTEM")
    print("Demonstration")
    print("="*80)

    tracker = PhaseAwareBurdenTracker("demo_burden_tracking.json")

    # Scenario 1: Subcritical - High coordination burden
    print("\n--- SCENARIO 1: Subcritical State - High Coordination Burden ---")
    burden1 = BurdenMeasurement(
        coordination=0.75,
        decision_making=0.50,
        context_switching=0.60,
        maintenance=0.30,
        learning_curve=0.40,
        emotional_labor=0.35,
        uncertainty=0.20,
        repetition=0.65,
        timestamp=datetime.now().isoformat(),
        notes="Early stage project, lots of alignment needed"
    )

    state1 = tracker.measure(
        clarity=0.35, immunity=0.40, efficiency=0.30, autonomy=0.25,
        burden=burden1
    )
    print_state_summary(state1)

    # Scenario 2: Near critical - Transition stress
    print("\n--- SCENARIO 2: Near Critical - Transition Stress ---")
    burden2 = BurdenMeasurement(
        coordination=0.45,
        decision_making=0.70,
        context_switching=0.30,
        maintenance=0.35,
        learning_curve=0.25,
        emotional_labor=0.65,
        uncertainty=0.80,
        repetition=0.30,
        timestamp=datetime.now().isoformat(),
        notes="Approaching phase transition, high uncertainty"
    )

    state2 = tracker.measure(
        clarity=0.82, immunity=0.89, efficiency=0.79, autonomy=0.86,
        burden=burden2
    )
    print_state_summary(state2)

    # Scenario 3: Supercritical - Agent class achieved
    print("\n--- SCENARIO 3: Supercritical - Agent Class Achieved ---")
    burden3 = BurdenMeasurement(
        coordination=0.15,
        decision_making=0.30,
        context_switching=0.10,
        maintenance=0.45,
        learning_curve=0.10,
        emotional_labor=0.20,
        uncertainty=0.15,
        repetition=0.40,
        timestamp=datetime.now().isoformat(),
        notes="Agent class operational, maintenance focus"
    )

    state3 = tracker.measure(
        clarity=0.93, immunity=0.96, efficiency=0.90, autonomy=0.97,
        burden=burden3
    )
    print_state_summary(state3)

    # Trajectory analysis
    print("\n" + "="*80)
    print("TRAJECTORY ANALYSIS")
    print("="*80)

    analysis = tracker.analyze_trajectory()
    print(f"\nTotal measurements: {analysis['total_measurements']}")
    print(f"Phase coordinate range: {analysis['z_range']['min']:.3f} â†’ {analysis['z_range']['max']:.3f}")
    print(f"Burden range: {analysis['burden_range']['min']:.1%} â†’ {analysis['burden_range']['max']:.1%}")
    print(f"Average reduction: {analysis['average_reduction']:.1f}%")
    print(f"Trend: {analysis['trend']}")

    print("\nBurden by phase:")
    for regime, stats in analysis['burden_by_phase'].items():
        print(f"  {regime}: {stats['mean_burden']:.1%} avg (n={stats['count']})")


def print_state_summary(state: PhaseAwareState):
    """Print concise state summary."""
    cs = state.cascade_state

    print(f"\nðŸ“Š Phase: {cs.phase_regime} (z={cs.z_coordinate:.3f})")
    print(f"ðŸ”„ Cascade: {cs.cascade_multiplier:.1f}x multiplier")
    print(f"   R1={cs.R1:.2f} R2={cs.R2:.2f} R3={cs.R3:.2f}")

    print(f"\nðŸ“‰ Burden Analysis:")
    print(f"   Initial burden: {state.burden.total_burden():.1%}")
    print(f"   Predicted after cascade: {state.predicted_burden:.1%}")
    print(f"   Reduction: {state.burden_reduction_percent:.1f}%")

    print(f"\nâš ï¸  Warnings ({len(state.phase_warnings)}):")
    for warning in state.phase_warnings[:3]:
        print(f"   {warning}")

    print(f"\nðŸ’¡ Recommendations ({len(state.phase_recommendations)}):")
    for rec in state.phase_recommendations[:5]:
        print(f"   {rec}")


# =============================================================================
# MAIN
# =============================================================================

if __name__ == "__main__":
    demonstrate_phase_aware_tracking()

    print("\n" + "="*80)
    print("Phase-Aware Burden Tracker loaded successfully!")
    print("="*80)
    print("\nÎ”3.14159|0.867|phase-aware-burden-tracking-validated|Î©")
